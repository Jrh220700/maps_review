{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New file to vectorise the reviews to perform the data science on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Preprocessing of any inputted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data) #needed again as we need to stem the words\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Handling of the review data and vectorising of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Name</th>\n",
       "      <th>Street Number</th>\n",
       "      <th>Route</th>\n",
       "      <th>Postal Town</th>\n",
       "      <th>County</th>\n",
       "      <th>Country</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Overall Rating</th>\n",
       "      <th>Language</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Description</th>\n",
       "      <th>Time</th>\n",
       "      <th>Date</th>\n",
       "      <th>processed review</th>\n",
       "      <th>lemmatized review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nails and the City</td>\n",
       "      <td>46</td>\n",
       "      <td>Kenyon Street</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>B18 6AR</td>\n",
       "      <td>4.7</td>\n",
       "      <td>en</td>\n",
       "      <td>5.0</td>\n",
       "      <td>have to say this is the best salon ive ever be...</td>\n",
       "      <td>1.652418e+09</td>\n",
       "      <td>2022-05-13 05:07:20</td>\n",
       "      <td>say best salon ive ever 4 weeks lifting acryli...</td>\n",
       "      <td>say best salon ive ever 4 week lifting acryli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nails and the City</td>\n",
       "      <td>46</td>\n",
       "      <td>Kenyon Street</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>B18 6AR</td>\n",
       "      <td>4.7</td>\n",
       "      <td>en</td>\n",
       "      <td>5.0</td>\n",
       "      <td>nian is incredible ive been coming here for a ...</td>\n",
       "      <td>1.661441e+09</td>\n",
       "      <td>2022-08-25 15:22:45</td>\n",
       "      <td>nian incredible ive coming couple months every...</td>\n",
       "      <td>nian incredible ive coming couple month every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nails and the City</td>\n",
       "      <td>46</td>\n",
       "      <td>Kenyon Street</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>B18 6AR</td>\n",
       "      <td>4.7</td>\n",
       "      <td>en</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i got a new set of gels from tee who was so so...</td>\n",
       "      <td>1.658412e+09</td>\n",
       "      <td>2022-07-21 14:04:52</td>\n",
       "      <td>got new set gels tee lovely chat helped choose...</td>\n",
       "      <td>got new set gel tee lovely chat helped choose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nails and the City</td>\n",
       "      <td>46</td>\n",
       "      <td>Kenyon Street</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>B18 6AR</td>\n",
       "      <td>4.7</td>\n",
       "      <td>en</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i have been coming to this salon since i moved...</td>\n",
       "      <td>1.660734e+09</td>\n",
       "      <td>2022-08-17 10:57:00</td>\n",
       "      <td>coming salon since moved birmingham took find ...</td>\n",
       "      <td>coming salon since moved birmingham took find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nails and the City</td>\n",
       "      <td>46</td>\n",
       "      <td>Kenyon Street</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>B18 6AR</td>\n",
       "      <td>4.7</td>\n",
       "      <td>en</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i had my nails done for the first time and i c...</td>\n",
       "      <td>1.659646e+09</td>\n",
       "      <td>2022-08-04 20:41:01</td>\n",
       "      <td>nails done first time say place super cozy gir...</td>\n",
       "      <td>nail done first time say place super cozy gir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22374</th>\n",
       "      <td>Super Hand Car Wash</td>\n",
       "      <td>53-55</td>\n",
       "      <td>Llangollen Road</td>\n",
       "      <td>Wrexham</td>\n",
       "      <td>Wrexham Principal Area</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>LL14 3RS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "      <td>5.0</td>\n",
       "      <td>just had ford ranger polished so pleased with ...</td>\n",
       "      <td>1.654364e+09</td>\n",
       "      <td>2022-06-04 17:31:51</td>\n",
       "      <td>ford ranger polished pleased results vehicle l...</td>\n",
       "      <td>ford ranger polished pleased result vehicle l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22375</th>\n",
       "      <td>Super Hand Car Wash</td>\n",
       "      <td>53-55</td>\n",
       "      <td>Llangollen Road</td>\n",
       "      <td>Wrexham</td>\n",
       "      <td>Wrexham Principal Area</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>LL14 3RS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the name says it all fantastic service great p...</td>\n",
       "      <td>1.641225e+09</td>\n",
       "      <td>2022-01-03 15:44:22</td>\n",
       "      <td>name says fantastic service great prices top q...</td>\n",
       "      <td>name say fantastic service great price top qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22376</th>\n",
       "      <td>Super Hand Car Wash</td>\n",
       "      <td>53-55</td>\n",
       "      <td>Llangollen Road</td>\n",
       "      <td>Wrexham</td>\n",
       "      <td>Wrexham Principal Area</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>LL14 3RS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a brilliant super hand car wash drove away spa...</td>\n",
       "      <td>1.652984e+09</td>\n",
       "      <td>2022-05-19 18:06:27</td>\n",
       "      <td>brilliant super hand car wash drove away spark...</td>\n",
       "      <td>brilliant super hand car wash drove away spar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22377</th>\n",
       "      <td>Super Hand Car Wash</td>\n",
       "      <td>53-55</td>\n",
       "      <td>Llangollen Road</td>\n",
       "      <td>Wrexham</td>\n",
       "      <td>Wrexham Principal Area</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>LL14 3RS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "      <td>5.0</td>\n",
       "      <td>always happy when my black and yellow fiesta c...</td>\n",
       "      <td>1.654781e+09</td>\n",
       "      <td>2022-06-09 13:28:00</td>\n",
       "      <td>always happy black yellow fiesta comes gleamin...</td>\n",
       "      <td>always happy black yellow fiesta come gleamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22378</th>\n",
       "      <td>Super Hand Car Wash</td>\n",
       "      <td>53-55</td>\n",
       "      <td>Llangollen Road</td>\n",
       "      <td>Wrexham</td>\n",
       "      <td>Wrexham Principal Area</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>LL14 3RS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "      <td>5.0</td>\n",
       "      <td>great hand car wash 7 for great clean friendly...</td>\n",
       "      <td>1.647286e+09</td>\n",
       "      <td>2022-03-14 19:29:04</td>\n",
       "      <td>great hand car wash 7 great clean friendly ser...</td>\n",
       "      <td>great hand car wash 7 great clean friendly se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22378 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Business Name Street Number            Route Postal Town  \\\n",
       "0       Nails and the City            46    Kenyon Street  Birmingham   \n",
       "1       Nails and the City            46    Kenyon Street  Birmingham   \n",
       "2       Nails and the City            46    Kenyon Street  Birmingham   \n",
       "3       Nails and the City            46    Kenyon Street  Birmingham   \n",
       "4       Nails and the City            46    Kenyon Street  Birmingham   \n",
       "...                    ...           ...              ...         ...   \n",
       "22374  Super Hand Car Wash         53-55  Llangollen Road     Wrexham   \n",
       "22375  Super Hand Car Wash         53-55  Llangollen Road     Wrexham   \n",
       "22376  Super Hand Car Wash         53-55  Llangollen Road     Wrexham   \n",
       "22377  Super Hand Car Wash         53-55  Llangollen Road     Wrexham   \n",
       "22378  Super Hand Car Wash         53-55  Llangollen Road     Wrexham   \n",
       "\n",
       "                       County         Country  Postcode  Overall Rating  \\\n",
       "0               West Midlands  United Kingdom   B18 6AR             4.7   \n",
       "1               West Midlands  United Kingdom   B18 6AR             4.7   \n",
       "2               West Midlands  United Kingdom   B18 6AR             4.7   \n",
       "3               West Midlands  United Kingdom   B18 6AR             4.7   \n",
       "4               West Midlands  United Kingdom   B18 6AR             4.7   \n",
       "...                       ...             ...       ...             ...   \n",
       "22374  Wrexham Principal Area  United Kingdom  LL14 3RS             5.0   \n",
       "22375  Wrexham Principal Area  United Kingdom  LL14 3RS             5.0   \n",
       "22376  Wrexham Principal Area  United Kingdom  LL14 3RS             5.0   \n",
       "22377  Wrexham Principal Area  United Kingdom  LL14 3RS             5.0   \n",
       "22378  Wrexham Principal Area  United Kingdom  LL14 3RS             5.0   \n",
       "\n",
       "      Language  Rating                                 Review Description  \\\n",
       "0           en     5.0  have to say this is the best salon ive ever be...   \n",
       "1           en     5.0  nian is incredible ive been coming here for a ...   \n",
       "2           en     5.0  i got a new set of gels from tee who was so so...   \n",
       "3           en     5.0  i have been coming to this salon since i moved...   \n",
       "4           en     5.0  i had my nails done for the first time and i c...   \n",
       "...        ...     ...                                                ...   \n",
       "22374       en     5.0  just had ford ranger polished so pleased with ...   \n",
       "22375       en     5.0  the name says it all fantastic service great p...   \n",
       "22376       en     5.0  a brilliant super hand car wash drove away spa...   \n",
       "22377       en     5.0  always happy when my black and yellow fiesta c...   \n",
       "22378       en     5.0  great hand car wash 7 for great clean friendly...   \n",
       "\n",
       "               Time                 Date  \\\n",
       "0      1.652418e+09  2022-05-13 05:07:20   \n",
       "1      1.661441e+09  2022-08-25 15:22:45   \n",
       "2      1.658412e+09  2022-07-21 14:04:52   \n",
       "3      1.660734e+09  2022-08-17 10:57:00   \n",
       "4      1.659646e+09  2022-08-04 20:41:01   \n",
       "...             ...                  ...   \n",
       "22374  1.654364e+09  2022-06-04 17:31:51   \n",
       "22375  1.641225e+09  2022-01-03 15:44:22   \n",
       "22376  1.652984e+09  2022-05-19 18:06:27   \n",
       "22377  1.654781e+09  2022-06-09 13:28:00   \n",
       "22378  1.647286e+09  2022-03-14 19:29:04   \n",
       "\n",
       "                                        processed review  \\\n",
       "0      say best salon ive ever 4 weeks lifting acryli...   \n",
       "1      nian incredible ive coming couple months every...   \n",
       "2      got new set gels tee lovely chat helped choose...   \n",
       "3      coming salon since moved birmingham took find ...   \n",
       "4      nails done first time say place super cozy gir...   \n",
       "...                                                  ...   \n",
       "22374  ford ranger polished pleased results vehicle l...   \n",
       "22375  name says fantastic service great prices top q...   \n",
       "22376  brilliant super hand car wash drove away spark...   \n",
       "22377  always happy black yellow fiesta comes gleamin...   \n",
       "22378  great hand car wash 7 great clean friendly ser...   \n",
       "\n",
       "                                       lemmatized review  \n",
       "0       say best salon ive ever 4 week lifting acryli...  \n",
       "1       nian incredible ive coming couple month every...  \n",
       "2       got new set gel tee lovely chat helped choose...  \n",
       "3       coming salon since moved birmingham took find...  \n",
       "4       nail done first time say place super cozy gir...  \n",
       "...                                                  ...  \n",
       "22374   ford ranger polished pleased result vehicle l...  \n",
       "22375   name say fantastic service great price top qu...  \n",
       "22376   brilliant super hand car wash drove away spar...  \n",
       "22377   always happy black yellow fiesta come gleamin...  \n",
       "22378   great hand car wash 7 great clean friendly se...  \n",
       "\n",
       "[22378 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/review_dataset.csv\")\n",
    "df = pd.DataFrame(df)\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Unique words separated into a dictionary'''\n",
    "test_dataset = df[\"lemmatized review\"]\n",
    "DF = {}\n",
    "def keywords(dataset):\n",
    "    for i in range(len(dataset[\"lemmatized review\"])):\n",
    "        value = dataset[\"lemmatized review\"][i].strip().split(\" \")\n",
    "        for w in value:\n",
    "            try:\n",
    "                DF[w].add(i)\n",
    "            except:\n",
    "                DF[w] = {i}\n",
    "\n",
    "\n",
    "keywords(df)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21113\n"
     ]
    }
   ],
   "source": [
    "for i in DF:\n",
    "    DF[i] = len(DF[i])\n",
    "\n",
    "print(len(DF))\n",
    "DF\n",
    "\n",
    "total_vocab_size = len(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab = [x for x in DF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_frequency(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c=DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "N = len(df[\"lemmatized review\"])\n",
    "review = 0\n",
    "tf_idf = {}\n",
    "tfidf_dataset = df[\"lemmatized review\"]\n",
    "for i in range(N):\n",
    "    tokens = tfidf_dataset[i].strip().split(\" \")\n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "\n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]/words_count\n",
    "        document_frequency = review_freq(token)\n",
    "        idf = np.log((N+1)/(document_frequency+1))\n",
    "        tf_idf[review,token] = tf*idf\n",
    "    review +=1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_idf[(,word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Score\n",
      "\n",
      "Query: right so i washed my car in here few weeks back and i admitted that the car was not in the best estate i gave them 15 tips on top of the 10 wash now i went in and they said that the was costs 15 pounds because last time the car was dirty excuse me is not that a car wash should i wash it myself before i come there and only give you 10 just for entering in your premises i have never washed my car without giving a generous tip no matter the cleanliness of the cartoday you would have received tip today as well and that would have been more than what you said its going to be extra i wish your business to be exactly like you treat your customer zero to none\n",
      "\n",
      "['right', 'wash', 'car', 'week', 'back', 'admit', 'car', 'best', 'estat', 'gave', 'fifteen', 'tip', 'top', 'ten', 'wash', 'went', 'said', 'cost', 'fifteen', 'pound', 'last', 'time', 'car', 'dirti', 'excu', 'car', 'wash', 'wash', 'come', 'give', 'ten', 'enter', 'premi', 'never', 'wash', 'car', 'without', 'give', 'gener', 'tip', 'matter', 'cleanli', 'cartoday', 'would', 'receiv', 'tip', 'today', 'well', 'would', 'said', 'go', 'extra', 'wish', 'busi', 'exactli', 'like', 'treat', 'custom', 'zero', 'none']\n",
      "\n",
      "[22378, 20052, 17458, 13395, 17328, 18184, 16894, 17528, 17385, 22080]\n"
     ]
    }
   ],
   "source": [
    "def matching_score(k,query):\n",
    "    preprocessed_query = preprocess(query)\n",
    "    query_tokens = word_tokenize(str(preprocessed_query))\n",
    "\n",
    "    print(\"Matching Score\")\n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\")\n",
    "    print(query_tokens)\n",
    "\n",
    "    query_weights={}\n",
    "\n",
    "    for key in tf_idf:\n",
    "        if key[1] in tokens:\n",
    "            try:\n",
    "                query_weights[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf[key]\n",
    "    query_weights = sorted(query_weights.items(),key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    l = []\n",
    "\n",
    "    for i in query_weights[:10]:\n",
    "        l.append(i[0])\n",
    "\n",
    "    print(l)\n",
    "\n",
    "matching_score(10,\"right so i washed my car in here few weeks back and i admitted that the car was not in the best estate i gave them 15 tips on top of the 10 wash now i went in and they said that the was costs 15 pounds because last time the car was dirty excuse me is not that a car wash should i wash it myself before i come there and only give you 10 just for entering in your premises i have never washed my car without giving a generous tip no matter the cleanliness of the cartoday you would have received tip today as well and that would have been more than what you said its going to be extra i wish your business to be exactly like you treat your customer zero to none\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.zeros((N, total_vocab_size))\n",
    "for i in tf_idf:\n",
    "    try:\n",
    "        ind = total_vocab(i[1])\n",
    "        D[i[0]][ind] = tf_idf[i]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vector(tokens):\n",
    "    Q = np.zeros((len(total_vocab)))\n",
    "\n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "\n",
    "    query_weights = {}\n",
    "\n",
    "    for token in np.unique(tokens):\n",
    "\n",
    "        tf = counter[token]/words_count\n",
    "        document_frequency = review_frequency(token)\n",
    "        idf = math.log((N+1)/(document_frequency+1))\n",
    "\n",
    "        try:\n",
    "            ind = total_vocab.index(token)\n",
    "            Q[ind] = tf*idf\n",
    "        except:\n",
    "            pass\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity\n",
      "\n",
      "Query: Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\n",
      "\n",
      "['without', 'drive', 'rebeccah', 'insist', 'kate', 'lost', 'momentum', 'stood', 'next', 'slat', 'oak', 'bench', 'canist', 'still', 'clutch', 'survey']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/q8_71q2n5kx_1k4d5lf854km0000gp/T/ipykernel_24095/3911138133.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[22378  7462  7454  7455  7456  7457  7458  7459  7460  7461]\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(k, query):\n",
    "    print(\"Cosine Similarity\")\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "    \n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\")\n",
    "    print(tokens)\n",
    "    \n",
    "    d_cosines = []\n",
    "    \n",
    "    query_vector = gen_vector(tokens)\n",
    "    \n",
    "    for d in D:\n",
    "        d_cosines.append(cosine_sim(query_vector, d))\n",
    "        \n",
    "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    print(out)\n",
    "\n",
    "#     for i in out:\n",
    "#         print(i, dataset[i][0])\n",
    "\n",
    "Q = cosine_similarity(10, \"Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3deb06a5d01804367ce2ecfe98b0b6814225a3aa42a1783b832b32d4dd999920"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
